{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfZgRqsIDvvkSlpx7T8epG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlimax/API_Rest_do_zero_com_colab/blob/main/Embeddings_Google_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Um Pouco Sobre Embeddings\n",
        "Computadores entendem a lógica booleana e trabalham manipulando entidades numéricas. Logo, para processarem a linguagem natural (NLP), é preciso transformá-la em uma representação numérica que possa carregar as propriedades semânticas presentes em nossa comunicação.\n",
        "\n",
        "Por isso, ao lidar com textos, imagens e sons, desenvolveram-se os métodos chamados de \"Embedding\", que literalmente significam incorporação ou embutimento.\n",
        "\n",
        "Na prática, vamos embutir um conceito, ideia ou dado num espaço matemático (aí vêm duas perguntas: na matemática, o que é um objeto no espaço e por que pensar em espaço?).\n",
        "\n",
        "Pensamos em \"espaço\" por um motivo fundamental: a geometria nos permite calcular distâncias. Se transformarmos palavras em coordenadas espaciais, conceitos com significados semelhantes (como \"Rei\" e \"Rainha\") terão vetores geometricamente próximos. Conceitos não relacionados estarão distantes. Ao atribuir coordenadas, criamos essencialmente um vetor; por isso, os métodos de embedding também são chamados de vetorização. Assim, é possível estabelecer comparações semânticas entre palavras por métodos matemátios como distância euclidiana, similaridade de cosseno, etc.\n",
        "\n",
        "Antes dessa abordagem espacial, os algoritmos mais comuns eram do tipo que fazem a contagem da presença de uma palavra num documento e atribuem uma importância a ela (como o TF-IDF), ainda muito comuns em motores de busca. Mas medir a importância de uma palavra no texto não está necessariamente capturando suas propriedades semânticas.\n",
        "\n",
        "Para mais informações, consulte:\n",
        "\n",
        "- **Guia de Embeddings Gemini:** https://ai.google.dev/gemini-api/docs/embeddings"
      ],
      "metadata": {
        "id": "pIBccoQ_ZtBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Como Processar Dados Para Embedding.\n",
        "\n",
        "Primeiramente, assim como nos modelos de LLM a unidade mínima de processamento de texto é o **token**, na vetorização de documentos introduzimos o **chunk** (fragmento ou pedaço) como uma unidade de informação. Enquanto o **token** é a \"peça\" atômica que a máquina lê, o **chunk** é o bloco de texto (uma frase, parágrafo ou seção) que escolhemos para **representar uma ideia completa no espaço vetorial**. Portanto, ainda estamos trabalhando com **tokens**, mas o conjunto de **tokens** que formam um contexto específico é o que chamamos de **chunk**.\n",
        "\n",
        "Dessa maneira, um documento grande como um livro, é subdivido em chunks, e essa divisão se torna muito importante por esses dois motivos fundamentais:\n",
        "\n",
        "- **Limite técnico:** As APIs possuem um limite máximo de tokens que conseguem processar e vetorizar por requisição.\n",
        "\n",
        "- **Foco semântico:** Um documento longo aborda múltiplos assuntos e nuances. Se você vetorizá-lo por completo de uma só vez, os significados matemáticos se diluem e se misturam, gerando um vetor \"genérico\" e impreciso. Ao dividir em chunks (como parágrafos ou seções), cada vetor carrega um significado forte e altamente específico, o que torna a busca muito mais exata.\n",
        "\n",
        "Por fim, você pode pensar em vetorizar um dado para diferentes fins:\n",
        "\n",
        "Task (Ação) | Descrição | Exemplo\n",
        "---|---|---\n",
        "**RETRIEVAL_QUERY** (Fazer busca) | Pergunta curta otimizada para atuar como termo de busca. | \"Como calcular a concorrência?\"\n",
        "**RETRIEVAL_DOCUMENT** (Guardar no banco) | Texto para o banco de dados, otimizado para ser encontrado pela Query. | Trecho de um edital em PDF.\n",
        "**SEMANTIC_SIMILARITY** (Comparar) | Mede a distância entre frases para checar se significam a mesma coisa. | Avaliar paráfrases ou achar textos duplicados.\n",
        "**CLASSIFICATION** (Classificar) | Prepara o vetor para algoritmos de aprendizado supervisionado. | Prever diagnóstico de diabetes a partir de laudos.\n",
        "**CLUSTERING** (Agrupar) | Prepara vetores para algoritmos não supervisionados, agrupando assuntos semelhantes. | Agrupar estudos sobre ilhas de calor urbano."
      ],
      "metadata": {
        "id": "SVBBAIHm7FlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.0 Baixa e importa o SDK python e bibliotecas."
      ],
      "metadata": {
        "id": "trX-QPbq2yjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "D2tq1CD3gvlC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Configura a chave"
      ],
      "metadata": {
        "id": "5ZnN6WTq29dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=user_key)"
      ],
      "metadata": {
        "id": "ItpZnuGpka38"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.0 Fazer vetorização"
      ],
      "metadata": {
        "id": "EF0SxvXG2_wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ver a lista de modelos"
      ],
      "metadata": {
        "id": "7em5yNADQebO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'embedContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7WnQLu96QhY4",
        "outputId": "23a2fdc9-c32b-4a26-fc30-9ae1fe2383db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos o método `embed_content()` para fazer a vetorização do conteúdo. Ele possui parâmetros para você definir qual modelo de embedding vai usar, o conteúdo a ser codificado e principalmente qual a tarefa (task) você quer destinar ao vetor."
      ],
      "metadata": {
        "id": "X1HNtfjv3_dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = genai.embed_content(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    content=\"Como calcular a concorrência de uma prova?\",\n",
        "    task_type=\"retrieval_query\"\n",
        ")\n",
        "\n",
        "# Você enviou 1 input para embedding, então gerou 1 output como vetor.\n",
        "print(\"Frase vetorizada: \", str(result[\"embedding\"])[:50], \"... TRIMMED]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DOcWyNMnlMGv",
        "outputId": "8cfd4021-065c-48b3-c9ee-18b340776cd7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase vetorizada:  [0.0052197427, 0.007644003, 0.04510661, -0.0542397 ... TRIMMED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obs:** `retrivial_document` exige um título porque ele funciona como uma \"âncora contextual\" para os seus chunks. Imagine que você dividiu um Código de Conduta da empresa em 50 parágrafos; ao atribuir o mesmo título a todos eles, você garante que o algoritmo entenda que todos pertencem ao mesmo documento, evitando que esses vetores fiquem \"órfãos\" ou percam parte do contexto original quando armazenados no banco de dados."
      ],
      "metadata": {
        "id": "iCoQwzwjJdfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = genai.embed_content(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    content=[\n",
        "        \"O tomate, apesar de ser usado em saladas, é botanicamente uma fruta.\",\n",
        "        \"A maçã possui uma polpa crocante e é rica em fibras.\",\n",
        "        \"A banana é uma das frutas mais consumidas no Brasil e nasce em cachos.\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Enciclopédia de Frutas\" # Este título ancora o contexto de todos os itens acima\n",
        ")\n",
        "\n",
        "# Você enviou uma lista de inputs para fazer o embedding, então gerou uma lista de vetores como outputo, por isso iterar com for.\n",
        "print(\"Frases vetorizadas:\")\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Ai-_fq08JRBH",
        "outputId": "1ccb0a83-34de-402a-b790-0f0f6a1ea521"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frases vetorizadas:\n",
            "[-0.0013930693, 0.015898436, 0.008572805, -0.05027 ... TRIMMED ...\n",
            "[-0.009155744, 0.025684193, 0.0148765445, -0.03721 ... TRIMMED ...\n",
            "[-0.012072629, 0.005662022, -0.00047756982, -0.046 ... TRIMMED ...\n"
          ]
        }
      ]
    }
  ]
}